# ASGI와 비동기(Async) 처리: 서버가 느려지는 이유부터 FastAPI 적용 지점까지

## 0. 서론: 오늘 주제의 한 문장

현대 웹 서버가 느려지는 가장 본질적인 이유는 대개 CPU가 부족해서가 아니라, 데이터베이스·외부 API·네트워크·파일 시스템 등 **외부 세계의 응답을 기다리는 I/O 대기 시간**이 크기 때문이다. 전통적인 동기(Blocking) 실행 모델에서는 이 기다림이 곧 실행 흐름의 정지로 이어져 동시 처리 능력이 급격히 떨어진다. 반면, 비동기(Async) 실행 모델은 기다려야 하는 순간에 실행 흐름을 붙잡지 않고 다른 작업을 처리하도록 하여, 같은 자원으로 더 많은 요청을 처리하는 동시성(Concurrency)을 확보한다. ASGI는 이러한 비동기 시대의 요구를 표준 인터페이스로 정리한 것이며, Uvicorn은 그 표준을 실제 네트워크·이벤트 루프 위에서 실행해 주는 엔진이다. FastAPI는 ASGI 기반 위에서, I/O가 많은 서비스에서 높은 처리량을 내도록 설계되었다.

> **발표 핵심 문장(요약)**  
> “서버는 계산보다 기다림이 많고, 비동기는 그 기다림을 겹쳐 쓰는 기술이며, ASGI는 그 비동기 실행을 표준화한 계약이다.”

---

## 1. 왜 ‘클라이언트–서버’ 구조가 되었는가 (아주 간단히)

웹의 초기에는 비교적 단순한 문서 전달이 중심이었으나, 시간이 흐르면서 웹은 “문서”를 넘어 “서비스”가 되었다. 사용자는 단순히 페이지를 읽는 것이 아니라, 로그인하고, 결제하고, 게시글을 쓰고, 검색하며, 실시간 상호작용을 수행하게 되었다. 이러한 흐름 속에서 서비스는 다음 요구를 강하게 갖게 된다.

1. **데이터와 정책의 중앙 관리**  
    사용자 데이터(회원정보, 주문내역 등)와 서비스 정책(권한, 요금제, 추천 로직 등)을 모든 사용자에게 일관되게 적용하려면, 데이터와 로직이 한곳(서버)에서 관리되는 편이 합리적이다. 클라이언트마다 로직을 분산하면 버전 불일치, 보안 취약, 데이터 무결성 붕괴가 쉽게 발생한다.
    
2. **업데이트와 확장성**  
    서비스가 바뀔 때마다 모든 사용자 기기를 업데이트하는 것은 현실적으로 어렵다. 반면 서버에 로직이 모여 있으면 서버만 업데이트해도 전체 서비스가 즉시 갱신된다. 또한 트래픽이 증가하면 서버를 증설하거나 분산하는 방식으로 확장할 수 있다.
    
3. **보안과 신뢰 경계**  
    클라이언트는 사용자의 기기이며, 서비스 제공자가 완전히 통제할 수 없다. 따라서 중요한 검증(인증/인가, 결제, 데이터 검증)은 서버에서 수행하는 것이 보안적으로 자연스럽다.
    

이러한 이유로 웹은 **클라이언트는 요청을 보내고, 서버는 요청을 처리하여 응답을 돌려주는 구조**로 발전해 왔다. 다만 이 구조가 굳어질수록, 서버는 동시에 수많은 요청을 처리해야 하는 “병목 지점”이 되었고, 결국 서버 설계의 핵심은 “단일 요청의 속도” 못지않게 “동시 처리 능력”이 되었다.

---

## 2. 서버를 OS 관점으로 보기: 서버는 결국 무엇을 하는가

웹 프레임워크를 먼저 배우면 서버가 마치 “함수 호출”처럼 보이기 쉽다. 그러나 운영체제(OS) 관점에서 서버는 다음 순환을 반복하는 프로그램이다.

> **서버의 본질**
> 
> 1. 소켓을 열고(port listen)
>     
> 2. 연결이 오면 accept
>     
> 3. 요청을 읽고(read)
>     
> 4. 외부 작업을 하고(DB/외부 API/파일)
>     
> 5. 응답을 쓰고(write)
>     

이 다섯 단계는 매우 단순해 보이지만, 실제 성능 병목은 대부분 4번 “외부 작업”과 3·5번 “네트워크 I/O”에서 발생한다. 이를 이해하기 위해서는 커널(운영체제)의 버퍼·스케줄링·대기 상태의 개념을 함께 떠올리는 것이 중요하다.

### 2.1 서버와 클라이언트는 실제로 어떻게 통신하는가

클라이언트가 “요청을 보낸다”는 말은, 결국 네트워크 위에서 **바이트(byte)**가 이동한다는 뜻이다. 서버는 그 바이트를 받아 HTTP라는 규칙으로 해석한다.

- 클라이언트는 서버의 IP:PORT로 TCP 연결을 시도한다.
    
- 운영체제 커널은 TCP 핸드셰이크를 처리하고 연결 상태를 만든다.
    
- 서버 프로세스는 `accept()`로 연결을 받아 전용 소켓(파일 디스크립터)을 얻는다.
    
- 클라이언트가 보낸 HTTP 요청 바이트는 커널의 수신 버퍼에 쌓인다.
    
- 서버는 `read()`/`recv()`로 커널 버퍼에서 바이트를 사용자 공간으로 가져온다.
    
- 서버는 그 바이트를 파싱해 “요청(메서드, 경로, 헤더, 바디)”로 해석한다.
    

즉, 서버가 받는 것은 처음부터 끝까지 바이트이며, 요청 객체는 그 바이트를 **서버 측 런타임이 해석하여 만든 추상화**이다.

### 2.2 서버가 느려지는 지점: ‘계산’이 아니라 ‘대기’

서버가 느려지는 핵심은 보통 “CPU 계산이 느려서”가 아니다. 대개는 다음과 같은 대기 시간이 누적되기 때문이다.

1. **요청 읽기(read)가 늦어짐**  
    클라이언트 네트워크가 느리거나 패킷이 지연되면, 서버는 충분한 바이트가 도착할 때까지 읽기를 마칠 수 없다.
    
2. **DB 조회가 늦어짐**  
    DB 조회는 사실상 네트워크 왕복 + DB 내부 실행(인덱스/디스크/락)이다. 서버는 결과가 올 때까지 기다린다.
    
3. **외부 API 호출이 늦어짐**  
    외부 API는 네트워크 지연, TLS 핸드셰이크, 상대 서버 부하, 레이트 리밋 등으로 지연이 커질 수 있다.
    
4. **파일 I/O가 늦어짐**  
    캐시에 없으면 디스크 접근이 필요하며, 디스크는 CPU보다 훨씬 느린 장치다.
    
5. **응답 쓰기(write)가 늦어짐(백프레셔)**  
    클라이언트가 느리게 받거나 네트워크가 혼잡하면 송신 버퍼가 차서 `send()` 자체가 막힐 수 있다.
    

이처럼 서버 처리 시간의 상당 부분은 “CPU로 계산하는 시간”이 아니라 “외부 응답을 기다리는 시간”이다.

---

## 3. Blocking I/O: 왜 “기다림”이 문제를 일으키는가

### 3.1 Blocking의 정의(운영체제 관점)

Blocking I/O란, 어떤 I/O 작업이 즉시 완료될 수 없을 때, 그 작업을 호출한 실행 흐름(스레드)이 **커널에 의해 대기 상태로 전환되어**, 결과가 준비될 때까지 다음 코드를 진행하지 못하는 방식을 말한다.

- 데이터가 아직 오지 않았으면 `read()`는 기다린다.
    
- DB 응답이 아직이면 드라이버 호출은 기다린다.
    
- 송신 버퍼가 가득 찼으면 `send()`는 기다린다.
    

여기서 중요한 점은 “대기 상태”가 단지 느린 것이 아니라, **동시 처리 관점에서 실행 흐름을 묶어버린다**는 점이다.

### 3.2 동기 + Blocking 환경에서 발생하는 현상: 직렬화

서버가 요청을 처리하는 실행 흐름이 하나뿐이거나, 실행 흐름 수가 제한되어 있다면, 한 요청이 I/O를 기다리는 동안 다른 요청을 처리할 자리가 부족해진다. 결국 요청은 줄을 서게 되고, 처리 흐름은 **직렬화**된다.

예를 들어 요청마다 DB 조회가 200ms 걸린다면,

- 동기/블로킹 모델에서는 200ms 대기가 요청마다 누적되기 쉬우며,
    
- 동시 요청이 많아질수록 대기 시간이 곧 전체 응답 지연으로 전이된다.
    

이 지점에서 “동시성 확보”는 서버 성능의 핵심 과제가 된다.

---

## 4. Sync vs Async vs Parallel: 반드시 구분해야 하는 이유

이 파트는 “단어를 정확히 정의하는 것”만으로도 발표의 설득력이 크게 올라간다.

### 4.1 Sync(동기)

동기란, 한 작업이 끝날 때까지 현재 실행 흐름이 기다리고, 완료된 뒤 다음 단계로 진행하는 방식이다. 동기 코드는 호출 스택이 단순하며 직관적이다. 문제는 동기가 I/O 대기와 결합될 때이다. 대기 중에는 실행 흐름이 묶이고, 그 흐름이 담당하던 다른 요청을 처리할 수 없다.

### 4.2 Async(비동기)

비동기란, 어떤 작업이 완료되기를 기다려야 하는 순간에 실행 흐름을 붙잡지 않고, 그동안 다른 작업을 처리하다가, 준비가 되었을 때 다시 돌아와 이어서 실행하는 방식이다.  
여기서 핵심은 대기 시간을 겹쳐 쓰는 동시성(Concurrency)이다. 비동기는 “물리적으로 동시에 실행”이 아니라, “실행을 잘게 쪼개어 대기 시간 동안 다른 일을 할 수 있게” 만드는 것이다.

> **발표에서 꼭 강조할 문장**  
> “Async는 동시에 달린다는 의미가 아니라, 기다림을 양보하는 방식이다.”

### 4.3 Parallel(병렬)

병렬은 여러 CPU 코어를 활용해 작업이 물리적으로 동시에 실행되는 것을 의미한다. 멀티프로세스/멀티코어 사용이 대표적이다. 즉 병렬은 하드웨어 자원을 늘려 계산을 동시에 수행한다.

> **발표에서 꼭 박아야 할 문장**  
> “Async ≠ Parallel. 비동기는 대기 관리이고, 병렬은 코어를 쓰는 것이다.”

### 4.4 I/O bound vs CPU bound

- I/O bound: 병목이 네트워크/DB/디스크 대기인 경우. **Async가 특히 효과적**이다.
    
- CPU bound: 병목이 계산 자체인 경우. 이벤트 루프가 계산에 묶이면 다른 작업을 돌릴 여지가 없으므로, Async만으로는 한계가 있다. 이때는 워커/프로세스로 분산하거나 작업 큐를 사용한다.
    

---

## 5. Python 비동기의 최소 핵심: Event Loop, Coroutine, await, 그리고 흔한 실수

### 5.1 Event Loop

이벤트 루프는 “준비된 작업(Task)을 실행하고, I/O나 타이머처럼 기다려야 하는 작업은 등록해 두었다가, 준비되면 다시 실행하는 관리자”이다. 즉, 이벤트 루프는 다음을 동시에 수행한다.

- ready 큐의 코루틴을 조금씩 실행
    
- OS로부터 “읽기 가능/쓰기 가능” 같은 이벤트 수신
    
- 타이머 기반 이벤트(예: sleep) 관리
    
- 완료된 이벤트가 있으면 해당 작업을 다시 ready로 전환
    

### 5.2 Coroutine / await

`async def`는 “중단/재개 가능한 실행 단위(코루틴)”를 만든다.  
`await`는 단순히 “기다린다”가 아니라, 더 정확히는 다음 의미를 가진다.

- 지금 이 지점에서는 당장 진행할 수 없으니,
    
- 제어권을 이벤트 루프에 돌려주고,
    
- 해당 작업이 준비되면 다시 이 코루틴을 재개하도록 예약한다.
    

즉 `await`는 **양보(yield) + 재개 예약**이다.

### 5.3 가장 흔한 실수: async 함수 안에서 블로킹 호출

`async def` 안에서 `time.sleep()` 같은 블로킹 함수를 호출하면, 그 순간 이벤트 루프를 담당하는 스레드 자체가 멈춰 버린다. 이는 “이 코루틴만 멈추는” 것이 아니라, 같은 이벤트 루프 위의 모든 작업이 함께 멈추는 결과를 낳는다. 따라서 비동기 코드에서는 `await asyncio.sleep()`처럼 “루프에 등록하고 제어권을 넘기는” 방식으로 대기해야 한다.

여기서 핵심 교훈은 다음과 같다.

> “비동기 함수 안에서 블로킹을 호출하면 비동기는 무력화된다.”  
> sleep뿐 아니라 동기 HTTP 클라이언트, 동기 DB 호출, 무거운 CPU 계산도 같은 위험을 가진다.

---

## 6. 게이트웨이 인터페이스란 무엇인가: 서버와 앱의 계약

### 6.1 왜 게이트웨이가 필요한가

웹 시스템에서 “서버”와 “애플리케이션”은 역할이 다르다.

- 서버: 소켓/연결 관리, 프로토콜 파싱, 이벤트 루프 운영, 실제 네트워크 I/O
    
- 앱: 비즈니스 로직, 라우팅, 요청 처리 결과 생성
    

이 둘이 분리되어야 다음이 가능해진다.

- 서버 구현을 바꾸어도 앱 로직은 유지된다.
    
- 앱 프레임워크를 바꾸어도 서버 운영 방식은 유지된다.
    
- 표준 규약을 통해 생태계(서버/미들웨어/프레임워크)가 확장된다.
    

이 “서버와 앱 사이의 표준 계약”이 바로 게이트웨이 인터페이스이며, 파이썬에서는 대표적으로 WSGI와 ASGI가 있다.

---

## 7. WSGI vs ASGI: 구조적 차이와 시대적 요구

### 7.1 WSGI: 전통적 동기 요청-응답 모델

WSGI는 기본 철학이 동기 요청-응답이다. 한 요청을 처리하는 흐름이 기본적으로 “막히면 막힌다.” 동시성을 확보하려면 보통 스레드/프로세스 수를 늘려서 처리한다. 또한 WebSocket처럼 연결이 길게 유지되는 지속 연결을 표준 인터페이스 차원에서 자연스럽게 담기가 어렵다. 스트리밍·양방향 이벤트 같은 요구는 WSGI 모델과 결이 맞지 않거나 구현이 불리하다.

### 7.2 ASGI: 비동기 시대의 이벤트 기반 인터페이스

ASGI는 Async를 1급 시민으로 다룬다. 요청을 “단발성 함수 호출”로만 보지 않고, 연결과 이벤트(send/receive)의 흐름으로 본다. 따라서 HTTP뿐 아니라 WebSocket, Streaming, Lifespan(스타트업/셧다운) 이벤트 등을 자연스럽게 지원한다. 또한 I/O 대기가 큰 서비스에서 이벤트 루프 기반 동시성을 활용하기에 유리하다.

> **발표 결론 문장**  
> “ASGI는 단순히 ‘빠른 인터페이스’가 아니라, 현대 웹의 연결·이벤트·동시성 요구를 표준 계약으로 담아낸 것이다.”

---

## 8. Uvicorn과 ASGI 서버: ‘실행 엔진’의 실체

### 8.1 Uvicorn은 무엇을 하는가

Uvicorn은 ASGI 서버로서 다음 기능을 수행한다.

1. **네트워크에서 연결을 받고 관리한다**  
    **listen/accept/read/write를 수행하며 커널 버퍼와 소켓 상태를 다룬다.**
    
2. HTTP/WebSocket을 파싱하고 상태를 유지한다  
    들어오는 바이트를 HTTP 요청/웹소켓 메시지로 해석한다.
    
3. 이벤트 루프 위에서 ASGI 앱을 실행한다  
    ASGI 규약에 따라 `scope`, `receive`, `send`를 구성하고, FastAPI 앱을 이벤트 루프에서 실행한다.
    
4. 많은 연결을 효율적으로 스케줄링한다  
    대기 중인 연결은 실행 흐름을 점유하지 않도록 하고, 준비된 이벤트만 처리하여 동시성을 높인다.
    

즉 Uvicorn은 “FastAPI를 실행해 주는 프로그램”일 뿐 아니라, **비동기 동시성을 실제로 가능하게 만드는 런타임**이다.

### 8.2 worker 개념(얕게): CPU bound는 워커/프로세스가 중요해진다

비동기 모델은 I/O bound에서 강하지만, CPU bound에서는 한계가 있다. CPU 계산이 길어지면 이벤트 루프가 묶여 다른 요청을 처리하지 못한다. 따라서 CPU 작업이 많다면 워커(프로세스)를 늘려 멀티코어 병렬로 분산하는 전략이 필요해질 수 있다.

> **실무형 요약**  
> “Async는 I/O에 강하고, CPU는 워커로 분산한다.”

---

## 9. FastAPI에서 Async가 실제로 적용되는 지점

FastAPI에서 “async를 쓴다”는 말은 단순히 `async def`로 엔드포인트를 작성한다는 뜻을 넘어, **I/O 경로 전체를 비동기 친화적으로 구성한다**는 뜻에 가깝다. 실제 적용 지점은 다음과 같이 정리된다.

### 9.1 async가 특히 의미 있는 지점(I/O 경로)

1. 외부 API 호출  
    외부 HTTP 호출은 네트워크 대기 시간이 크다. 이때 비동기 HTTP 클라이언트를 사용하고 `await`로 호출하면, 기다리는 동안 다른 요청을 처리할 수 있다.
    
2. DB 접근  
    DB 조회 역시 대기가 핵심이다. 비동기 DB 드라이버(또는 비동기 ORM 설정)를 사용하면 이벤트 루프 기반으로 동시성을 얻을 수 있다.
    
3. Streaming/SSE/WebSocket  
    지속 연결과 스트리밍은 대기와 이벤트의 연속이다. ASGI 기반 FastAPI는 이러한 모델을 자연스럽게 다룰 수 있다.
    
4. Dependency Injection에 포함되는 I/O  
    FastAPI의 DI(Depends)는 요청 처리 전에 “현재 사용자 확인, DB 세션 준비” 같은 공통 작업을 수행할 때 자주 쓰인다. 이 작업들이 I/O를 포함한다면 async 기반으로 구성하는 것이 동시성 측면에서 유리하다.
    

### 9.2 async여도 효과가 제한되는 지점(CPU bound)

- 이미지 처리, 대규모 루프 계산, 무거운 암호화/압축, 모델 추론처럼 CPU 자체가 병목인 경우  
    → async만으로는 빨라지지 않으며, 워커/프로세스 또는 작업 큐로 분리하는 것이 적절하다.
    

### 9.3 비동기를 망치는 전형 패턴

- `async def` 안에서 `time.sleep()` 호출
    
- `requests` 같은 동기 HTTP 호출
    
- 동기 DB 드라이버 사용으로 대기가 직렬화되는 경우
    
- 이벤트 루프 위에서 긴 CPU 계산을 수행하여 루프를 붙잡는 경우
    

여기서 결론은 단순하다.

> “FastAPI에서 async의 효과는 ‘async 함수 선언’이 아니라, 실제 대기 지점이 await 가능해야 발생한다.”

---

## 10. 데모(된다면): 짧고 확실하게 “느낌”을 보여주는 실험

발표에서 데모는 길게 할 필요가 없다. 오히려 짧고 확실한 대비가 핵심이다. 추천되는 데모의 목적은 다음 하나다.

- **“블로킹은 서버 전체를 묶고, non-blocking await는 동시성을 만든다”를 눈으로 보여준다.**
    

가장 안전한 형태는 다음과 같은 비교 실험이다.

1. 같은 서버에서 동시에 2개의 요청을 보낸다.
    
2. 서버 내부에서 2초 대기를 넣는다.
    
3. `time.sleep(2)`일 때는 요청이 서로 발목을 잡아 “둘 다 늦게” 끝나는 느낌이 강해진다.
    
4. `await asyncio.sleep(2)`일 때는 “기다리는 동안 다른 요청이 처리되는” 동시성 감각이 나타난다.
    

이 데모는 외부 API나 DB가 없어도 가능하여 실패 확률이 낮다. 발표 시간도 짧게 유지할 수 있다.

---

# 결론: 전체 흐름의 핵심 논리

1. 웹은 클라이언트–서버 구조로 발전했고, 서버는 동시에 많은 요청을 받는다.
    
2. 서버는 OS 관점에서 소켓을 열고 연결을 받고 읽고 처리하고 쓴다.
    
3. 서버가 느려지는 원인은 대개 계산이 아니라 I/O 대기이며, Blocking은 실행 흐름을 묶는다.
    
4. 비동기는 기다림에서 제어권을 양보하여 동시성을 확보하는 방식이며 병렬과 다르다.
    
5. 파이썬 비동기는 이벤트 루프/코루틴/await로 구성되고, 블로킹 호출은 이를 무력화한다.
    
6. WSGI는 전통적 동기 요청-응답 모델이고, ASGI는 비동기·이벤트 기반 요구를 표준화한다.
    
7. Uvicorn은 ASGI 서버로서 네트워크·프로토콜·이벤트 루프 위에서 FastAPI 앱을 실행한다.
    
8. FastAPI에서 async의 실질 효과는 I/O 경로(HTTP/DB/스트리밍/웹소켓)에서 나타나며, CPU bound는 워커/프로세스로 분산해야 한다.
    

---

원하면, 이 레포트 문장을 거의 그대로 써서 **“슬라이드 12~15장 분량”으로** (각 슬라이드 제목 / 핵심 bullet / 발표 대본 / 전환 멘트)까지 한 번에 재구성해줄게. 또한 데모를 하려면 “가장 실패 확률이 낮은 데모 구성”으로 진행 순서도 같이 만들어줄 수 있어.